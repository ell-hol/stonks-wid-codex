{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "few-shot_object_detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/u1Jq9j8yegFIqPmF/n7T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ell-hol/stonks-wid-codex/blob/main/few_shot_object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlXlmj82CO4Y"
      },
      "source": [
        "\"\"\"\n",
        "Defines a pytorch end-to-end object detection model.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = fasterrcnn_resnet50_fpn(\n",
        "            pretrained=False,\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained_backbone=False,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "D7ZGXY-oCgaR",
        "outputId": "4b26b788-c915-4a04-b604-8c65f305a44f"
      },
      "source": [
        "        \n",
        "\"\"\"\n",
        "Defines a few-shot object detection Dataset based on COCO.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import PIL\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from utils import get_image_path, get_image_url\n",
        "\n",
        "class CocoDataset(Dataset):\n",
        "  def __init__(self, dataset_name, split, num_classes, num_examples):\n",
        "    super().__init__()\n",
        "    self.dataset_name = dataset_name\n",
        "    self.split = split\n",
        "    self.num_classes = num_classes\n",
        "    self.num_examples = num_examples\n",
        "  def __len__(self):\n",
        "    return len(self.image_filenames)\n",
        "\n",
        "class CocoDataset(Dataset):\n",
        "  \"\"\"\n",
        "  A few-shot object detection dataset based on COCO.\n",
        "  \"\"\"\n",
        "  def __init__(self, dataset_name, split, num_classes, num_examples):\n",
        "    super().__init__()\n",
        "    self.dataset_name = dataset_name\n",
        "    self.split = split\n",
        "    self.num_classes = num_classes\n",
        "    self.num_examples = num_examples\n",
        "\n",
        "    if self.dataset_name == 'train':\n",
        "      path = Path(f'/mnt/c/Users/James/Downloads/annotations/instances_train2017.json')\n",
        "    else:\n",
        "      path = Path(f'/mnt/c/Users/James/Downloads/annotations/instances_val2017.json')\n",
        "\n",
        "    data = json.load(path.open())\n",
        "    self.categories = [cat for cat in data['categories'] if cat['name'] in [f'{c}' for c in range(num_classes)]][:num_classes]\n",
        "    self.category_ids = [cat['id'] for cat in self.categories]\n",
        "    self.category_names = [cat['name'] for cat in self.categories]\n",
        "\n",
        "    self.image_ids = [image['id'] for image in data['images']]\n",
        "    self.image_id_to_filename = {image['id']: image['file_name'] for image in data['images']}\n",
        "    self.image_id_to_url = {image['id']: get_image_url(image['file_name']) for image in data['images']}\n",
        "    self.image_filenames = [image['file_name'] for image in data['images']]\n",
        "\n",
        "    self.image_id_to_bboxes = {}\n",
        "    self.image_id_to_category_id = {}\n",
        "    for ann in data['annotations']:\n",
        "      if ann['category_id'] in self.category_ids:\n",
        "        if ann['image_id'] not in self.image_id_to_bboxes:\n",
        "          self.image_id_to_bboxes[ann['image_id']] = []\n",
        "        if ann['image_id'] not in self.image_id_to_category_id:\n",
        "          self.image_id_to_category_id[ann['image_id']] = []\n",
        "        self.image_id_to_bboxes[ann['image_id']].append(ann['bbox'])\n",
        "        self.image_id_to_category_id[ann['image_id']].append(ann['category_id'])\n",
        "\n",
        "    self.image_id_to_bboxes = {k: np.array(v) for k, v in self.image_id_to_bboxes.items()}\n",
        "    self.image_id_to_category_id = {k: np.array(v) for k, v in self.image_id_to_category_id.items()}\n",
        "\n",
        "    self.nearest_neighbors = NearestNeighbors(n_neighbors=num_examples)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_filenames)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_id = self.image_ids[index]\n",
        "    filename = self.image_id_to_filename[image_id]\n",
        "    url = self.image_id_to_url[image_id]\n",
        "    bboxes = self.image_id_to_bboxes[image_id]\n",
        "    category_id = self.image_id_to_category_id[image_id]\n",
        "\n",
        "    image = PIL.Image.open(get_image_path(self.dataset_name, filename))\n",
        "    image = np.array(image)\n",
        "\n",
        "    if len(bboxes) == 0:\n",
        "      bboxes = np.zeros((0, 4), dtype=np.float32)\n",
        "      category_id = np.zeros((0,), dtype=np.int32)\n",
        "    else:\n",
        "      bboxes = (bboxes - np.array([[0.0, 0.0, 0.0, 0.0]])) / np.array([[image.shape[1], image.shape[0], image.shape[1], image.shape[0]]])\n",
        "\n",
        "    # Randomly select num_examples bounding boxes\n",
        "    if len(bboxes) > self.num_examples:\n",
        "      idxs = np.random.choice(range(len(bboxes)), self.num_examples, replace=False)\n",
        "      bboxes = bboxes[idxs]\n",
        "      category_id = category_id[idxs]\n",
        "\n",
        "    # Randomly flip the image horizontally\n",
        "    if np.random.rand() < 0.5:\n",
        "      image = image[:, ::-1, :]\n",
        "      bboxes[:, [0, 2]] = 1.0 - bboxes[:, [2, 0]]\n",
        "\n",
        "    # Resize image and bounding boxes\n",
        "    image = PIL.Image.fromarray(image)\n",
        "    image = image.resize((224, 224), resample=PIL.Image.BILINEAR)\n",
        "    image = np.array(image)\n",
        "\n",
        "    bboxes = torch.tensor(bboxes, dtype=torch.float32)\n",
        "    category_id = torch.tensor(category_id, dtype=torch.int32)\n",
        "\n",
        "    return image, bboxes, category_id, filename"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-a178cafd2921>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    if ann['image_id'] not in self.image_id_to_bboxes:\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKc5yrGBC45i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}